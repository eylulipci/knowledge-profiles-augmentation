{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b843d7c-3106-4068-9300-0eb9998cb407",
   "metadata": {},
   "source": [
    "## Datasets for each Knowledge Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79155094-c754-4b29-bfef-ddb694acc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_profiles = [\"0000\", \"1000\", \"0110\", \"1110\", \"0111\"]\n",
    "base_dir_method = \"generation/generation_method/correct_responses/temp_1\"\n",
    "base_dir_simple = \"generation/generation_simple/correct_responses/temp_1\"\n",
    "\n",
    "for knowledge_profile in knowledge_profiles:\n",
    "\n",
    "    \n",
    "    df_method = read_synthetic_data(base_dir_method, knowledge_profile)\n",
    "    df_method.to_csv(f\"{knowledge_profile}_generated_data.csv\", index=False)\n",
    "\n",
    "    df_simple = read_synthetic_data(base_dir_simple, knowledge_profile)\n",
    "    df_simple.to_csv(f\"{knowledge_profile}_simple_generated_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5c8f9-2fc5-45b1-8449-e955bb152237",
   "metadata": {},
   "source": [
    "## Mixed Generated Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97fbb6-6d63-4a08-ad42-3194510c874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mixed_datasets(size=500, generation='simple'):\n",
    "    # Load data for each knowledge profile\n",
    "    data_frames = {}\n",
    "    for profile in knowledge_profiles:\n",
    "\n",
    "        if generation=='simple':\n",
    "            file_path = os.path.join(input_directory, f\"{profile}_simple_generated_data.csv\")\n",
    "            output_file = os.path.join(output_directory, f\"simple_mixed_data_{size}.csv\")\n",
    "        else:\n",
    "            file_path = os.path.join(input_directory, f\"{profile}_generated_data.csv\")\n",
    "            output_file = os.path.join(output_directory, f\"mixed_data_{size}.csv\")\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            data_frames[profile] = pd.read_csv(file_path)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    samples_per_profile = size // len(knowledge_profiles)\n",
    "    \n",
    "    # Sample equal numbers of rows from each profile\n",
    "    mixed_data = pd.concat([\n",
    "        df.sample(n=samples_per_profile, random_state=random.randint(0, 1000), replace=False)\n",
    "        for profile, df in data_frames.items()\n",
    "    ])\n",
    "\n",
    "    mixed_data = mixed_data.sample(frac=1, random_state=random.randint(0, 1000)).reset_index(drop=True)\n",
    "    mixed_data.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778d550-aece-4e06-b579-bc065d8c51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = \"augmented_datasets\"  \n",
    "output_directory = \"augmented_datasets\"  \n",
    "\n",
    "# create mixed datasets\n",
    "create_mixed_datasets(generated='method')\n",
    "create_mixed_datasets(generated='simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7bdad5-bcf1-411b-8c5d-5fcf8eb6226e",
   "metadata": {},
   "source": [
    "## Create Generated + Original Datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da65b8-be5f-4d1c-a500-7b645377b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base size for the generated dataset and original sizes for the original\n",
    "original_sizes = [100, 200, 300, 400]\n",
    "BASE_SIZE = 500\n",
    "\n",
    "for size in original_sizes:\n",
    "\n",
    "    train_path = \"path/to/original/data/train.csv\"\n",
    "    augmented_path = f\"generated_datasets/mixed_data_{BASE_SIZE}.csv\"\n",
    "    output_path = f\"generated_datasets/generated_original_{size}.csv\"\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    augmented_df = pd.read_csv(augmented_path)\n",
    "\n",
    "    # Rename columns in the generated dataset to match train_split.csv\n",
    "    augmented_df = augmented_df.rename(\n",
    "        columns={\n",
    "            \"text\": \"CONTRAPOSITION task\",\n",
    "            \"rubric1\": \"Statement of what should be proven: A proof by contraposition of an implication consists in showing that if x rational, then x^2 is rational. \",\n",
    "            \"rubric2\": \"Correct assumption: x is rational [Assumption] \",\n",
    "            \"rubric3\": \"Correct proof reasoning\",\n",
    "            \"rubric4\": \"Proof conclusion: By contraposition, if x^2 is irrational, then x is irrational.\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    sample_size = size \n",
    "    sampled_df = train_df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    combined_df = pd.concat([augmented_df, sampled_df], ignore_index=True)\n",
    "    shuffled_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    shuffled_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
